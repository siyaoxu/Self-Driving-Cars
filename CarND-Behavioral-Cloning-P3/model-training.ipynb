{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # load data\n",
    "# lines = []\n",
    "\n",
    "# with open('../../data/driving_log.csv') as csvfile:\n",
    "#     reader = csv.reader(csvfile)\n",
    "#     for line in reader:\n",
    "#         lines.append(line)\n",
    "        \n",
    "# images = []\n",
    "# measurements = []\n",
    "# for line in lines[1:]:\n",
    "#     source_path = line[0]\n",
    "#     filename = source_path.split('/'[-1])\n",
    "#     current_path = '../../data/IMG/' + filename[1]\n",
    "#     image = cv2.imread(current_path)\n",
    "#     images.append(image)\n",
    "#     measurement = float(line[3])\n",
    "#     measurements.append(measurement)\n",
    "    \n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "lines = []\n",
    "\n",
    "with open('../../data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "steering_correction = 0.2\n",
    "for line in lines[1:]:\n",
    "    # center image\n",
    "    source_path = line[0]\n",
    "    filename = source_path.split('/'[-1])\n",
    "    current_path = '../../data/IMG/' + filename[1]\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    measurement = float(line[3])\n",
    "    measurements.append(measurement)\n",
    "    # left image\n",
    "    source_path = line[1]\n",
    "    filename = source_path.split('/'[-1])\n",
    "    current_path = '../../data/IMG/' + filename[1]\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    left_measurement = measurement + steering_correction\n",
    "    measurements.append(left_measurement)\n",
    "    # right image\n",
    "    source_path = line[2]\n",
    "    filename = source_path.split('/'[-1])\n",
    "    current_path = '../../data/IMG/' + filename[1]\n",
    "    image = cv2.imread(current_path)\n",
    "    images.append(image)\n",
    "    right_measurement = measurement - steering_correction\n",
    "    measurements.append(right_measurement)\n",
    "    \n",
    "X_train = np.array(images)\n",
    "y_train = np.array(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24108, 160, 320, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def modelDef(X_train):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(lambda x: (x/255.0)-0.5,input_shape = X_train.shape[1:]))\n",
    "    # Convolution layer 1 input 160x320x3 output 160x320x8\n",
    "    model.add(Convolution2D(filters = 8, kernel_size = 5, activation = 'relu', padding = 'same'))\n",
    "    # Maxpooling layer 1 input 160x320x8 ouput 80x160x8\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    # Convolution layer 2 input 80x160x8 output 80x160x16\n",
    "    model.add(Convolution2D(filters = 16, kernel_size = 5, activation = 'relu', padding = 'same'))\n",
    "    # Maxpooling layer 2 input 80x160x16 ouput 40x80x16\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    # Convolution layer 3 input 40x80x16 output 40x80x16\n",
    "    model.add(Convolution2D(filters = 16, kernel_size = 5, activation = 'relu', padding = 'same'))\n",
    "    # Maxpooling layer 3 input 40x80x16 ouput 20x40x16\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    # Convolution layer 4 input 20x40x32 output 20x40x32\n",
    "    model.add(Convolution2D(filters = 32, kernel_size = 5, activation = 'relu', padding = 'same'))\n",
    "    # Maxpooling layer 4 input 20x40x32 ouput 10x20x32\n",
    "    model.add(MaxPooling2D())\n",
    "\n",
    "    # Flully connected layer 1 input 6400\n",
    "    model.add(Flatten())\n",
    "    # Fully connected layer 2 input 800\n",
    "    model.add(Dense(800))\n",
    "    # Fully connected layer 3 input 200\n",
    "    model.add(Dense(200))\n",
    "    # prediction\n",
    "    model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModel(X_train, y_train, model, loss='mse', optimizer='adam', validation_split = 0.2, shuffle = True, epochs = 10,\n",
    "               modelName = 'test_model.h5', ):\n",
    "    model.compile(loss = loss, optimizer = optimizer)\n",
    "    model.fit(X_train, y_train, validation_split = validation_split, shuffle=shuffle, epochs=epochs)\n",
    "    if modelName != '':\n",
    "        model.save(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19286 samples, validate on 4822 samples\n",
      "Epoch 1/5\n",
      "19286/19286 [==============================] - 80s - loss: 0.0816 - val_loss: 0.0125\n",
      "Epoch 2/5\n",
      "19286/19286 [==============================] - 77s - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 3/5\n",
      "19286/19286 [==============================] - 78s - loss: 0.0094 - val_loss: 0.0118\n",
      "Epoch 4/5\n",
      "19286/19286 [==============================] - 78s - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 5/5\n",
      "19286/19286 [==============================] - 77s - loss: 0.0085 - val_loss: 0.0108\n"
     ]
    }
   ],
   "source": [
    "# define and train the model\n",
    "model = modelDef(X_train)\n",
    "trainModel(model=model, X_train=X_train, y_train=y_train, modelName = 'test_model.h5', epochs = 5)\n",
    "# model.save('test_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
